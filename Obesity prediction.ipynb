{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":7479144,"sourceType":"datasetVersion","datasetId":4353512}],"dockerImageVersionId":30635,"isInternetEnabled":false,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# import library\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport warnings\nwarnings.filterwarnings('ignore')\n\npd.set_option('display.max_colwidth', 250)","metadata":{"execution":{"iopub.status.busy":"2024-01-28T13:46:23.174626Z","iopub.execute_input":"2024-01-28T13:46:23.175625Z","iopub.status.idle":"2024-01-28T13:46:23.181321Z","shell.execute_reply.started":"2024-01-28T13:46:23.175586Z","shell.execute_reply":"2024-01-28T13:46:23.180193Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"_________________________","metadata":{}},{"cell_type":"markdown","source":"# Dataset","metadata":{}},{"cell_type":"code","source":"# Import Dataset\ndf = pd.read_csv(\"obesity_data.csv\")\ndisplay(df.head(2),df.sample(2),df.tail(2))","metadata":{"execution":{"iopub.status.busy":"2024-01-28T13:46:23.194751Z","iopub.execute_input":"2024-01-28T13:46:23.195192Z","iopub.status.idle":"2024-01-28T13:46:23.237446Z","shell.execute_reply.started":"2024-01-28T13:46:23.195159Z","shell.execute_reply":"2024-01-28T13:46:23.236364Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Dataset Information\ndisplay(df.describe(),\npd.DataFrame({\n    'feature': df.columns.values,\n    'dtypes': [df[col].dtype for col in df.columns],\n    'n_unique': df.nunique().values,\n    'n_nan': [df[col].isna().sum() for col in df.columns],\n    'n_dupe': [df.duplicated().sum() for row in df.columns],\n    'sample_unique': [df[col].unique() for col in df.columns]\n    })\n)\nprint(f'''\n      Columns that having missing value\\t= {df.isnull().any().sum()} : {df.columns[df.isna().any()].tolist()}\n      Columns that are clean\\t\\t= {df.shape[1] - df.isnull().any().sum()} : {df.columns[df.notna().all()].tolist()}\n      Columns\\t\\t\\t\\t= {df.shape[1]}\n      Rows that having missing value\\t= {df.isnull().sum().sum()}\n      Rows\\t\\t\\t\\t= {df.shape[0]}\n      Percentage of missing value\\t= {(df.isnull().sum().sum()/np.product(df.shape)) * 100}\n      ''')","metadata":{"execution":{"iopub.status.busy":"2024-01-28T13:46:23.248645Z","iopub.execute_input":"2024-01-28T13:46:23.249083Z","iopub.status.idle":"2024-01-28T13:46:23.32147Z","shell.execute_reply.started":"2024-01-28T13:46:23.249047Z","shell.execute_reply":"2024-01-28T13:46:23.320618Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Obesity Distribution\nnumeric_columns = df.select_dtypes(include=np.number).columns.tolist()\n\n# Adjust the number of rows and columns in the subplot grid\nnum_rows = (len(numeric_columns) + 1) // 3 + (1 if len(numeric_columns) % 3 != 0 else 0)\nnum_cols = min(len(numeric_columns), 3)\n\nfig, axes = plt.subplots(nrows=num_rows, ncols=num_cols, figsize=(15, 4 * num_rows))\naxes = axes.flatten()\n\nfor i, col in enumerate(numeric_columns[:5]):\n    for obesity_level in df[\"ObesityCategory\"].unique():\n        subset_data = df[df[\"ObesityCategory\"] == obesity_level]\n        colors = sns.color_palette()[list(df[\"ObesityCategory\"].unique()).index(obesity_level)]\n        sns.kdeplot(data=subset_data, x=col, fill=True, ax=axes[i], color=colors)\n\n        middle_value = subset_data[col].median()\n        axes[i].axvline(middle_value, linestyle='dashed', linewidth=2, color=colors)\n\n    axes[i].set_title(f\"{col} Distribution\")\n    axes[i].legend()\n\n# Remove empty subplots if any\nfor j in range(num_rows * num_cols - len(numeric_columns)):\n    fig.delaxes(axes[-(j+1)])\n    \nplt.suptitle(\"Obesity Distribution\",y=1.02, fontsize=15)\nplt.tight_layout()\nplt.show()\n","metadata":{"execution":{"iopub.status.busy":"2024-01-28T13:46:23.322957Z","iopub.execute_input":"2024-01-28T13:46:23.323294Z","iopub.status.idle":"2024-01-28T13:46:26.692475Z","shell.execute_reply.started":"2024-01-28T13:46:23.323264Z","shell.execute_reply":"2024-01-28T13:46:26.691262Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Outliers\ndef find_anomalies(data, column_name):\n    q1, q3 = data.quantile([0.25, 0.75])\n    iqr = q3 - q1\n    limit = iqr * 1.5\n    bot = q1 - limit\n    top = q3 + limit\n    outliers_count = ((data < (bot)) | (data > (top))).sum()\n\n    result = pd.DataFrame({\n        'Column': [column_name],\n        'IQR': [iqr],\n        'Lower Bound': [bot],\n        'Upper Bound': [top],\n        'Outliers': [outliers_count]\n    })\n    return result\n\ndf_outliers = pd.DataFrame(columns=['Column', 'IQR', 'Lower Bound', 'Upper Bound', 'Outliers'])\n\nfor column in numeric_columns:\n    result = find_anomalies(df[column], column)\n    df_outliers = pd.concat([df_outliers, result], ignore_index=True)\n    \n# Remove Outliers\nfor i,low,up in zip(df_outliers.Column.unique(),df_outliers[\"Lower Bound\"].unique(),df_outliers[\"Upper Bound\"].unique()):\n    df = df[(df[i] >= low) & (df[i] <= up)]\n\ndisplay(df_outliers)\nprint(f\"Numbers of Outliers Removed : {df_outliers['Outliers'].sum()}\")","metadata":{"execution":{"iopub.status.busy":"2024-01-28T13:46:26.693992Z","iopub.execute_input":"2024-01-28T13:46:26.694935Z","iopub.status.idle":"2024-01-28T13:46:26.735545Z","shell.execute_reply.started":"2024-01-28T13:46:26.694901Z","shell.execute_reply":"2024-01-28T13:46:26.734729Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Gender Obesity Distribution\nmale_counts = df[df['Gender'] == 'Male']['ObesityCategory'].value_counts()\nfemale_counts = df[df['Gender'] == 'Female']['ObesityCategory'].value_counts()\ngen_count = df.Gender.value_counts().reset_index(name = \"counts\")\ndata = [male_counts, female_counts]\ntitles = ['Male', 'Female']\n\n# Create Pie Plot\nfig, axes = plt.subplots(nrows=1, ncols=2, figsize=(10, 5))\n\nfor i in range(2):\n    axes[i].pie(data[i], labels=data[i].index, autopct='%1.1f%%', startangle=90, explode=(0.05, 0.05, 0.05, 0.05),\n               wedgeprops={'edgecolor': 'black', 'linewidth': 1, 'antialiased': True})\n    axes[i].set_title(titles[i])\n\n# Create a legend outside the subplots\nlegend_labels = [f'{index}: {count}' for index, count in zip(df.Gender.unique(), gen_count.counts)]\nlegend = plt.legend(legend_labels, title='Gender Counts', bbox_to_anchor=(1, 1), labelspacing=1, handlelength=0, handleheight=0)\n\nplt.suptitle(\"Gender Obesity Categories\", fontsize=15)\nplt.tight_layout()\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2024-01-28T13:46:26.737683Z","iopub.execute_input":"2024-01-28T13:46:26.738247Z","iopub.status.idle":"2024-01-28T13:46:27.186085Z","shell.execute_reply.started":"2024-01-28T13:46:26.738215Z","shell.execute_reply":"2024-01-28T13:46:27.185221Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Obesity Category Comparation\nCategory_counts = df['ObesityCategory'].value_counts()\n\nplt.pie(Category_counts, labels=Category_counts.index, autopct='%1.2f%%',  explode=(0.05, 0.05, 0.05, 0.05), startangle=90,\n        wedgeprops={'edgecolor': 'black', 'linewidth': 1, 'antialiased': True})\n\nlegend_labels = [f'{index}: {count}' for index, count in zip(Category_counts.index, Category_counts)]\nplt.legend(legend_labels, title='Category Counts',bbox_to_anchor=(1, 1))\n\nplt.suptitle(\"Obesity Category Comparation\", fontsize=15)\nplt.tight_layout()\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2024-01-28T13:46:27.187401Z","iopub.execute_input":"2024-01-28T13:46:27.187944Z","iopub.status.idle":"2024-01-28T13:46:27.524608Z","shell.execute_reply.started":"2024-01-28T13:46:27.187911Z","shell.execute_reply":"2024-01-28T13:46:27.523719Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Encode\nfrom sklearn.preprocessing import LabelEncoder\n\nlabel_encoder = LabelEncoder()\ndf[\"Gender\"] = label_encoder.fit_transform(df[\"Gender\"])\ndf[\"ObesityCategory\"] = label_encoder.fit_transform(df[\"ObesityCategory\"])\n\ndf.sample(5)","metadata":{"execution":{"iopub.status.busy":"2024-01-28T13:46:27.525972Z","iopub.execute_input":"2024-01-28T13:46:27.526504Z","iopub.status.idle":"2024-01-28T13:46:27.543014Z","shell.execute_reply.started":"2024-01-28T13:46:27.526471Z","shell.execute_reply":"2024-01-28T13:46:27.54206Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Correlation\nplt.figure(figsize=(10, 8))\nsns.heatmap(df.corr(), annot=True, cmap=\"coolwarm\", fmt=\".2f\", linewidths=.5)\nplt.title(\"Correlation Heatmap\")\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2024-01-28T13:46:27.544424Z","iopub.execute_input":"2024-01-28T13:46:27.545Z","iopub.status.idle":"2024-01-28T13:46:28.07663Z","shell.execute_reply.started":"2024-01-28T13:46:27.544967Z","shell.execute_reply":"2024-01-28T13:46:28.075833Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"________________","metadata":{}},{"cell_type":"markdown","source":"# Train Dataset","metadata":{}},{"cell_type":"code","source":"# Seen & Unseen\nfrom sklearn.model_selection import train_test_split\nseen, unseen = train_test_split(df, test_size=0.05, random_state=42)\nprint(f\"\"\"\nSeen = {seen.shape}\nUnseen = {unseen.shape}\"\"\")","metadata":{"execution":{"iopub.status.busy":"2024-01-28T13:46:28.077909Z","iopub.execute_input":"2024-01-28T13:46:28.078409Z","iopub.status.idle":"2024-01-28T13:46:28.08552Z","shell.execute_reply.started":"2024-01-28T13:46:28.078379Z","shell.execute_reply":"2024-01-28T13:46:28.084748Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Train Test Split\nX = seen.drop(\"ObesityCategory\", axis=1)\ny = seen[\"ObesityCategory\"]\n\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\nprint(f\"\"\"\nX_train = {X_train.shape}\nX_test = {X_test.shape}\"\"\")","metadata":{"execution":{"iopub.status.busy":"2024-01-28T13:46:28.088548Z","iopub.execute_input":"2024-01-28T13:46:28.089093Z","iopub.status.idle":"2024-01-28T13:46:28.100954Z","shell.execute_reply.started":"2024-01-28T13:46:28.08905Z","shell.execute_reply":"2024-01-28T13:46:28.100121Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Import Model\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.svm import SVC\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier\nfrom sklearn.naive_bayes import GaussianNB\nfrom sklearn.neural_network import MLPClassifier\nfrom xgboost import XGBClassifier\nfrom lightgbm import LGBMClassifier\nfrom sklearn.discriminant_analysis import LinearDiscriminantAnalysis, QuadraticDiscriminantAnalysis\nfrom sklearn.gaussian_process import GaussianProcessClassifier\nfrom sklearn.linear_model import RidgeClassifier\nfrom sklearn.linear_model import Perceptron\nfrom sklearn.ensemble import GradientBoostingClassifier\nfrom sklearn.linear_model import SGDClassifier\nfrom catboost import CatBoostClassifier\n\nlr = LogisticRegression(random_state=42)\nknn = KNeighborsClassifier()\nsvm = SVC(random_state=42)\ndt = DecisionTreeClassifier(random_state=42)\nrf = RandomForestClassifier(random_state=42)\nadaboost = AdaBoostClassifier(random_state=42)\nnb = GaussianNB()\nmlp = MLPClassifier(random_state=42)\nxgb = XGBClassifier(random_state=42)\nlgbm = LGBMClassifier(random_state=42)\nlda = LinearDiscriminantAnalysis()\nqda = QuadraticDiscriminantAnalysis()\ngp = GaussianProcessClassifier(random_state=42)\nridge = RidgeClassifier(random_state=42)\nperceptron = Perceptron(random_state=42)\ngbr = GradientBoostingClassifier(random_state=42)\nsgd = SGDClassifier(random_state=42)\ncb = CatBoostClassifier(random_state=42,verbose=0)\n\nmodels = [lr, knn, svm, dt, rf, adaboost, nb, mlp, xgb, lgbm, lda, qda, gp, ridge, perceptron, gbr, sgd, cb]","metadata":{"execution":{"iopub.status.busy":"2024-01-28T13:46:28.102069Z","iopub.execute_input":"2024-01-28T13:46:28.102904Z","iopub.status.idle":"2024-01-28T13:46:28.118898Z","shell.execute_reply.started":"2024-01-28T13:46:28.102873Z","shell.execute_reply":"2024-01-28T13:46:28.117744Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Model Benchmarking\nfrom sklearn.model_selection import cross_val_score, KFold, cross_val_predict\nfrom sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score, cohen_kappa_score, matthews_corrcoef\nfrom sklearn.preprocessing import label_binarize\n\naccuracy = []\nprecision = []\nrecall = []\nf1 = []\nkappa = []\nmcc = []\n\ncrossval = KFold(n_splits=5, shuffle=True, random_state=42)\n\nfor model in models:\n    \n    # Accuracy\n    model_cv_accuracy = cross_val_score(\n        model, \n        X, \n        y, \n        cv=crossval, \n        scoring='accuracy', \n        error_score='raise'\n    )\n    accuracy.append(model_cv_accuracy.mean())\n    \n    # Precision\n    y_pred = cross_val_predict(model, X, y, cv=crossval)\n    model_cv_precision = precision_score(y, y_pred, average=\"weighted\")\n    precision.append(model_cv_precision)\n\n    # Recall\n    model_cv_recall = recall_score(y, y_pred, average=\"weighted\")\n    recall.append(model_cv_recall)\n    \n    # F1 Score\n    model_cv_f1 = cross_val_score(\n        model, \n        X, \n        y, \n        cv=crossval, \n        scoring='f1_weighted', \n        error_score='raise',\n    )\n    f1.append(model_cv_f1.mean())\n    \n    # Cohen's Kappa\n    model_cv_kappa = cohen_kappa_score(y, y_pred)\n    kappa.append(model_cv_kappa)\n    \n    # Matthews Correlation Coefficient (MCC)\n    model_cv_mcc = matthews_corrcoef(y, y_pred)\n    mcc.append(model_cv_mcc)\n    \ndf_eval = pd.DataFrame({\n    'Model': [\n        'Logistic Regression',\n        'K-Nearest Neighbors',\n        'SVC',\n        'Decision Tree Classifier',\n        'Random Forest Classifier',\n        'AdaBoost Classifier',\n        'GaussianNB',\n        'MLP Classifier',\n        'XGBoost Classifier',\n        'LGBM Classifier',\n        'Linear Discriminant Analysis',\n        'Quadratic Discriminant Analysis',\n        'Gaussian Process Classifier',\n        'Ridge Classifier',\n        'Perceptron',\n        'Gradient Boosting Classifier',\n        'SGD Classifier',\n        'CatBoost Classifier'],\n    'Accuracy' : accuracy,\n    'Prec.' : precision,\n    'Recall' : recall,\n    'F1' : f1,\n    'Kappa' : kappa,\n    'MCC' : mcc\n})\ndf_eval.sort_values(by=\"Accuracy\", ascending=False)","metadata":{"execution":{"iopub.status.busy":"2024-01-28T13:46:28.12039Z","iopub.execute_input":"2024-01-28T13:46:28.120715Z","iopub.status.idle":"2024-01-28T13:48:33.574816Z","shell.execute_reply.started":"2024-01-28T13:46:28.120687Z","shell.execute_reply":"2024-01-28T13:48:33.573494Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Compare ROC-AUC Score & Classification Report\nlgbm.fit(X_train, y_train)\n\ny_pred_default = lgbm.predict(X_test)\ny_pred_proba_default = lgbm.predict_proba(X_test)\n\n# Apply softmax to get probabilities\ndef softmax(x):\n    exp_x = np.exp(x - np.max(x, axis=1, keepdims=True))\n    return exp_x / exp_x.sum(axis=1, keepdims=True)\ny_pred_proba_default_softmax = softmax(y_pred_proba_default)\n\nroc_auc_default = roc_auc_score(y_test, y_pred_proba_default_softmax, multi_class='ovr')\nreport_default = classification_report(y_test, y_pred_default)\n\nprint('ROC AUC Score Default LGBM Classifier : ', roc_auc_default)\nprint('\\nClassification Report Default LGBM Classifier : \\n', report_default)","metadata":{"execution":{"iopub.status.busy":"2024-01-28T13:48:33.576607Z","iopub.execute_input":"2024-01-28T13:48:33.577394Z","iopub.status.idle":"2024-01-28T13:48:34.461334Z","shell.execute_reply.started":"2024-01-28T13:48:33.577348Z","shell.execute_reply":"2024-01-28T13:48:34.460201Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Final Model\ndf_eval = df_eval[df_eval[\"Model\"]==\"LGBM Classifier\"]\ndf_eval['ROC-AUC'] = roc_auc_default\ndf_eval.reset_index(drop=True)","metadata":{"execution":{"iopub.status.busy":"2024-01-28T13:48:34.463032Z","iopub.execute_input":"2024-01-28T13:48:34.463349Z","iopub.status.idle":"2024-01-28T13:48:34.484578Z","shell.execute_reply.started":"2024-01-28T13:48:34.463321Z","shell.execute_reply":"2024-01-28T13:48:34.483651Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"___________________","metadata":{}},{"cell_type":"markdown","source":"# Evaluate","metadata":{}},{"cell_type":"code","source":"# Confusion Matrix\nfrom sklearn.metrics import confusion_matrix\nconf_matrix = confusion_matrix(y_test, y_pred_default)\n\nplt.figure(figsize=(8, 8))\nsns.heatmap(conf_matrix, annot=True, fmt='d', cmap='coolwarm', cbar=False)\n\nplt.title('Confusion Matrix - LGBM Classifier')\nplt.xlabel('Predicted Labels')\nplt.ylabel('True Labels')\n\nclass_labels = [\"Normal weight\", \"Obese\", \"Overweight\", \"Underweight\"]\ntick_marks = [0.5, 1.5, 2.5, 3.5]\nplt.xticks(tick_marks, class_labels)\nplt.yticks(tick_marks, class_labels)\n\nplt.tight_layout()\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2024-01-28T13:48:34.48602Z","iopub.execute_input":"2024-01-28T13:48:34.486336Z","iopub.status.idle":"2024-01-28T13:48:34.847201Z","shell.execute_reply.started":"2024-01-28T13:48:34.486309Z","shell.execute_reply":"2024-01-28T13:48:34.846047Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Testing Model\nNormal_Weight = df[df['ObesityCategory'] == 0]\nObese = df[df['ObesityCategory'] == 1]\nOver_Weight = df[df['ObesityCategory'] == 2]\nUnder_Weight = df[df['ObesityCategory'] == 3]\nmetrics = ['mean', 'median']\nresult_frames = []\n\nfor metric in metrics:\n    Normal_frame = getattr(Normal_Weight, metric)().to_frame().T\n    Obese_frame = getattr(Obese, metric)().to_frame().T\n    Over_frame = getattr(Over_Weight, metric)().to_frame().T\n    Under_frame = getattr(Under_Weight, metric)().to_frame().T\n    result_frames.append(pd.concat([Normal_frame.assign(label=f'Normal_{metric}'), \n                                    Obese_frame.assign(label=f'Obese_{metric}'),\n                                    Over_frame.assign(label=f'Over_{metric}'), \n                                    Under_frame.assign(label=f'Under_{metric}')],ignore_index=True))\n\ndfval = pd.concat(result_frames, ignore_index=True)\ndfval = dfval[['label'] + [col for col in dfval.columns if col != 'label']]\n\nprint(\"Before (Using mean & median of every columns based on ObesityCategory) :\")\ndisplay(dfval)\n\n# Result Testing Model\ndfval[\"Predicted ObesityCategory\"] = lgbm.predict(dfval.drop(columns={\"ObesityCategory\",\"label\"}))\nprint(\"After :\")\ndisplay(dfval)","metadata":{"execution":{"iopub.status.busy":"2024-01-28T13:48:34.848552Z","iopub.execute_input":"2024-01-28T13:48:34.849422Z","iopub.status.idle":"2024-01-28T13:48:34.914631Z","shell.execute_reply.started":"2024-01-28T13:48:34.84939Z","shell.execute_reply":"2024-01-28T13:48:34.913743Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Testing Model on Unseen\nunseen[\"Predicted ObesityCategory\"] = lgbm.predict(unseen.drop(columns={\"ObesityCategory\"}))\nunseen","metadata":{"execution":{"iopub.status.busy":"2024-01-28T13:48:34.915982Z","iopub.execute_input":"2024-01-28T13:48:34.916506Z","iopub.status.idle":"2024-01-28T13:48:34.945234Z","shell.execute_reply.started":"2024-01-28T13:48:34.916475Z","shell.execute_reply":"2024-01-28T13:48:34.944062Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Feature Importance\ninput_layer_weights = lgbm.feature_importances_\nfeature_weights = pd.DataFrame({'Feature': X.columns, 'Importance': input_layer_weights})\n\nfeature_weights.sort_values(by='Importance', ascending=True, inplace=True)\nfeature_weights.plot(kind='barh', x='Feature', y='Importance', legend=False)\nplt.title('Feature Importance in LightGBM Model')\nplt.xlabel('Importance')\nplt.ylabel('Feature')\n\nplt.tight_layout()\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2024-01-28T13:48:34.947103Z","iopub.execute_input":"2024-01-28T13:48:34.947841Z","iopub.status.idle":"2024-01-28T13:48:35.308984Z","shell.execute_reply.started":"2024-01-28T13:48:34.947798Z","shell.execute_reply":"2024-01-28T13:48:35.307791Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Conclusion","metadata":{}},{"cell_type":"markdown","source":"**1. Based on the modeling that has been conducted, Classification analysis has been successfully performed using a machine learning approach. In this analysis, the features \"BMI\" have been identified as the most influential ones for classifying 'ObesityCategory'.**\n\n**2. Based on the evaluation results of the Light Gradient Boosting Machine (LGBM) Classifier model, it is evident that the model exhibits exceptional performance in classifying the given dataset:**\n\n- **Accuracy:** The LGBM Classifier achieves an outstanding accuracy of 99.68%, indicating its ability to correctly classify instances with an exceptionally high level of precision.\n\n- **Precision:** With a precision score of 99.68%, the model showcases that 99.68% of its positive predictions are accurate, highlighting its reliability in correctly identifying positive cases.\n\n- **Recall:** The model demonstrates an impressive recall rate of 99.68%, signifying its capability to effectively capture 99.68% of all actual positive cases.\n\n- **F1 Score:** The F1 Score, standing at 99.68%, emphasizes the harmonious balance between precision and recall, reinforcing the model's robustness in handling both false positives and false negatives.\n\n- **Kappa Coefficient:** The Kappa coefficient attains a high value of 99.54%, indicating an exceptional agreement between the model's predictions and the actual classes.\n\n- **Matthews Correlation Coefficient (MCC):** With an MCC value of 99.54%, the model exhibits a strong and reliable relationship between its predictions and the actual classes.\n\n- **ROC-AUC:** The Area Under the ROC Curve (ROC-AUC) achieves a perfect value of 100%, showcasing the model's exceptional ability to distinguish between positive and negative classes with precision.\n\n**In conclusion, based on these evaluation metrics, it can be confidently asserted that the LGBM Classifier model excels in classifying the provided dataset. The exceptionally high values across accuracy, precision, recall, F1 Score, Kappa, MCC, and ROC-AUC collectively demonstrate the model's reliability and outstanding performance in handling the classification task for this specific dataset.**\n","metadata":{}}]}